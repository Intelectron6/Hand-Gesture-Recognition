{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OREKdZjsNehc",
        "outputId": "bfa8f973-4c0b-4afb-d1e6-fa929567355f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Self explanatory stuff\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from warnings import simplefilter\n",
        "\n",
        "dir_five = '/content/gdrive/MyDrive/EMG_Data/dataset_five'\n",
        "dir_two = '/content/gdrive/MyDrive/EMG_Data/dataset_peace'\n",
        "dir_one = '/content/gdrive/MyDrive/EMG_Data/dataset_one'\n",
        "\n",
        "# These lists will contain all data samples (for example, f1c1 = gesture five, channel 1)\n",
        "f1c1 = []\n",
        "f1c2 = []\n",
        "o1c1 = []\n",
        "o1c2 = []\n",
        "t1c1 = []\n",
        "t1c2 = []\n",
        "n1c1 = []\n",
        "n1c2 = []"
      ],
      "metadata": {
        "id": "AwHYUMqUSbcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading each csv file and appending data samples to respective lists based on labels\n",
        "# If label is 1, then data sample is appended to the list corresponding to csv file (one or two or five)\n",
        "# If label is 0, then data sample is appended to the list of no gesture/rest gesture\n",
        "\n",
        "for i in range(1,11):\n",
        "    f1 = pd.read_csv(dir_five + '/five_'+str(i)+'_labeled.csv')\n",
        "    o1 = pd.read_csv(dir_one + '/one_'+str(i)+'_labeled.csv')\n",
        "    t1 = pd.read_csv(dir_two + '/peace_'+str(i)+'_labeled.csv')\n",
        "\n",
        "    for i in range(len(f1['channel1_data'])):\n",
        "        if f1['channel_1_upper_label'][i] == 1:\n",
        "            f1c1.append(f1['channel1_data'][i])\n",
        "            f1c2.append(f1['channel2_data'][i])\n",
        "        else:\n",
        "            n1c1.append(f1['channel1_data'][i])\n",
        "            n1c2.append(f1['channel1_data'][i])\n",
        "\n",
        "    for i in range(len(o1['channel1_data'])):\n",
        "        if o1['channel_1_upper_label'][i] == 1:\n",
        "            o1c1.append(o1['channel1_data'][i])\n",
        "            o1c2.append(o1['channel2_data'][i])\n",
        "        else:\n",
        "            n1c1.append(o1['channel1_data'][i])\n",
        "            n1c2.append(o1['channel1_data'][i])\n",
        "\n",
        "    for i in range(len(t1['channel1_data'])):\n",
        "        if t1['channel_1_upper_label'][i] == 1:\n",
        "            t1c1.append(t1['channel1_data'][i])\n",
        "            t1c2.append(t1['channel2_data'][i])\n",
        "        else:\n",
        "            n1c1.append(t1['channel1_data'][i])\n",
        "            n1c2.append(t1['channel1_data'][i])\n",
        "\n",
        "print(\"Datapoints for rest:\", len(n1c1))\n",
        "print(\"Datapoints for five:\", len(f1c1))\n",
        "print(\"Datapoints for two: \", len(t1c1))\n",
        "print(\"Datapoints for one: \", len(o1c1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbGHZ54gTb3b",
        "outputId": "8c4d4bee-ec71-440d-8f62-466c9baf2f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datapoints for rest: 1334056\n",
            "Datapoints for five: 385423\n",
            "Datapoints for two:  509324\n",
            "Datapoints for one:  498466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating bins of 256 samples (this window is arbitrarily chosen; can be changed)\n",
        "\n",
        "five1 = []\n",
        "five2 = []\n",
        "for i in range(0,385024,256):\n",
        "    five1.append(f1c1[i:i+256])\n",
        "    five2.append(f1c2[i:i+256])\n",
        "\n",
        "two1 = []\n",
        "two2 = []\n",
        "for i in range(0,508928,256):\n",
        "    two1.append(t1c1[i:i+256])\n",
        "    two2.append(t1c2[i:i+256])\n",
        "\n",
        "one1 = []\n",
        "one2 = []\n",
        "for i in range(0,497664,256):\n",
        "    one1.append(o1c1[i:i+256])\n",
        "    one2.append(o1c2[i:i+256])\n",
        "\n",
        "rest1 = []\n",
        "rest2 = []\n",
        "for i in range(0,1331200,256):\n",
        "    rest1.append(n1c1[i:i+256])\n",
        "    rest2.append(n1c2[i:i+256])\n",
        "\n",
        "print(\"Number of bins:\", len(five1), len(two1), len(one1), len(rest1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cC1Ejg8iMhl",
        "outputId": "68fdbd32-3c14-4858-e73e-8863c2cf2c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of bins: 1504 1988 1944 5200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting time domain features from each bin\n",
        "\n",
        "def power(x):\n",
        "    p = 0\n",
        "    for i in x:\n",
        "        p = p + i*i\n",
        "    return p\n",
        "\n",
        "def rms(x):\n",
        "    r = 0\n",
        "    for i in x:\n",
        "        r = r + i*i\n",
        "    r = np.sqrt(r/len(x))\n",
        "    return r\n",
        "\n",
        "c1_amp, c2_amp = [], []\n",
        "c1_slp, c2_slp = [], []\n",
        "c1_pow, c2_pow = [], []\n",
        "c1_rms, c2_rms = [], []\n",
        "outp_label = []\n",
        "\n",
        "for i in range(len(five1)):\n",
        "    c1_amp.append(sum(five1[i]))\n",
        "    c2_amp.append(sum(five2[i]))\n",
        "    c1_pow.append(power(five1[i]))\n",
        "    c2_pow.append(power(five2[i]))\n",
        "    c1_rms.append(rms(five1[i]))\n",
        "    c2_rms.append(rms(five2[i]))\n",
        "    if i == 0:\n",
        "        c1_slp.append(0)\n",
        "        c2_slp.append(0)\n",
        "    else:\n",
        "        c1_slp.append(sum(five1[i])-sum(five1[i-1]))\n",
        "        c2_slp.append(sum(five2[i])-sum(five2[i-1]))\n",
        "    outp_label.append('five')\n",
        "\n",
        "for i in range(len(two1)):\n",
        "    c1_amp.append(sum(two1[i]))\n",
        "    c2_amp.append(sum(two2[i]))\n",
        "    c1_pow.append(power(two1[i]))\n",
        "    c2_pow.append(power(two2[i]))\n",
        "    c1_rms.append(rms(two1[i]))\n",
        "    c2_rms.append(rms(two2[i]))\n",
        "    if i == 0:\n",
        "        c1_slp.append(0)\n",
        "        c2_slp.append(0)\n",
        "    else:\n",
        "        c1_slp.append(sum(two1[i])-sum(two1[i-1]))\n",
        "        c2_slp.append(sum(two2[i])-sum(two2[i-1]))\n",
        "    outp_label.append('two')\n",
        "\n",
        "for i in range(len(rest1)):\n",
        "    c1_amp.append(sum(rest1[i]))\n",
        "    c2_amp.append(sum(rest2[i]))\n",
        "    c1_pow.append(power(rest1[i]))\n",
        "    c2_pow.append(power(rest2[i]))\n",
        "    c1_rms.append(rms(rest1[i]))\n",
        "    c2_rms.append(rms(rest2[i]))\n",
        "    if i == 0:\n",
        "        c1_slp.append(0)\n",
        "        c2_slp.append(0)\n",
        "    else:\n",
        "        c1_slp.append(sum(rest1[i])-sum(rest1[i-1]))\n",
        "        c2_slp.append(sum(rest2[i])-sum(rest2[i-1]))\n",
        "    outp_label.append('rest')\n",
        "\n",
        "for i in range(len(one1)):\n",
        "    c1_amp.append(sum(one1[i]))\n",
        "    c2_amp.append(sum(one2[i]))\n",
        "    c1_pow.append(power(one1[i]))\n",
        "    c2_pow.append(power(one2[i]))\n",
        "    c1_rms.append(rms(one1[i]))\n",
        "    c2_rms.append(rms(one2[i]))\n",
        "    if i == 0:\n",
        "        c1_slp.append(0)\n",
        "        c2_slp.append(0)\n",
        "    else:\n",
        "        c1_slp.append(sum(one1[i])-sum(one1[i-1]))\n",
        "        c2_slp.append(sum(one2[i])-sum(one2[i-1]))\n",
        "    outp_label.append('one')"
      ],
      "metadata": {
        "id": "D3ay6pMWijrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To-do: Extracting frequency domain features from each bin\n"
      ],
      "metadata": {
        "id": "iclygvH8uXeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing data for ML\n",
        "\n",
        "X = np.array([c1_amp, c2_amp, c1_slp, c2_slp, c1_rms, c2_rms, c1_pow, c2_pow]).T\n",
        "y = np.array(outp_label)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "print(np.shape(X), np.shape(y))\n",
        "\n",
        "X_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size=0.2, random_state=1) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O8WnyKiiKJ9",
        "outputId": "501c70e6-adf9-46d8-d9d8-2f776cb49674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10636, 8) (10636,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Kernel SVM and Random Forest classifiers using GridSearchCV and displaying results \n",
        "\n",
        "param_grid_kersvm = {'C': [1, 10, 100], \n",
        "                    'gamma': [0.1, 0.01, 0.001],\n",
        "                    'kernel': ['rbf']} \n",
        "\n",
        "param_grid_ranfor = {'max_depth': [4,8,12,16],\n",
        "                    'max_features': [2,4,6,8]}\n",
        "\n",
        "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "print(\"Kernel SVM\")\n",
        "grid_kersvm = GridSearchCV(estimator = SVC(), param_grid = param_grid_kersvm, cv = 5)\n",
        "grid_kersvm.fit(X_train, y_train)\n",
        "y_predict = grid_kersvm.predict(X_validate)\n",
        "print(\"balanced accuracy = \", balanced_accuracy_score(y_validate, y_predict))\n",
        "print(grid_kersvm.best_params_)\n",
        "print('Classification Report: \\n', classification_report(y_validate,y_predict))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_validate,y_predict))\n",
        "print()\n",
        "\n",
        "print(\"Random Forest\")\n",
        "grid_ranfor = GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_grid_ranfor, cv = 5)\n",
        "grid_ranfor.fit(X_train, y_train)\n",
        "y_predict = grid_ranfor.predict(X_validate)\n",
        "print(\"balanced accuracy = \", balanced_accuracy_score(y_validate, y_predict))\n",
        "print(grid_ranfor.best_params_)\n",
        "print('Classification Report: \\n', classification_report(y_validate,y_predict))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_validate,y_predict))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuxLEKzvWl1m",
        "outputId": "2fa0b7c9-bd09-4a0f-b298-05d47d10cd66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kernel SVM\n",
            "balanced accuracy =  0.9083612471401574\n",
            "{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        five       0.98      0.85      0.91       314\n",
            "         one       0.86      0.93      0.89       362\n",
            "        rest       0.94      1.00      0.97      1055\n",
            "         two       1.00      0.86      0.92       397\n",
            "\n",
            "    accuracy                           0.94      2128\n",
            "   macro avg       0.94      0.91      0.92      2128\n",
            "weighted avg       0.94      0.94      0.94      2128\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 268    7   39    0]\n",
            " [   1  335   25    1]\n",
            " [   2    0 1053    0]\n",
            " [   2   48    7  340]]\n",
            "\n",
            "Random Forest\n",
            "balanced accuracy =  0.9429172275096963\n",
            "{'max_depth': 16, 'max_features': 6}\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        five       0.98      0.93      0.95       314\n",
            "         one       0.90      0.94      0.92       362\n",
            "        rest       0.97      0.99      0.98      1055\n",
            "         two       0.98      0.91      0.94       397\n",
            "\n",
            "    accuracy                           0.96      2128\n",
            "   macro avg       0.96      0.94      0.95      2128\n",
            "weighted avg       0.96      0.96      0.96      2128\n",
            "\n",
            "Confusion Matrix: \n",
            " [[ 291    2   21    0]\n",
            " [   1  342   12    7]\n",
            " [   4    3 1048    0]\n",
            " [   2   32    3  360]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vk5UNHdVW-80"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}